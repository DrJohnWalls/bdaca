{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT:** make sure that you have the newest version of pandas (0.18 or higher) by running the following command (in the terminal):\n",
    "* sudo pip3 install pandas --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas and Statsmodels\n",
    "## Completing your data analysis workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use pandas and statsmodels today to show how the data analysis can be done completely in Python. \n",
    "\n",
    "Pandas is a package that allows us to work with datasets in a similar manner as in R (with dataframes) and, according to their own website, has the objective of becoming **the most powerful and flexible open source data analysis / manipulation tool available in any language**. \n",
    "\n",
    "It's up to you to decide whether that is (already) true or not, but this tutorial will demonstrate some of its capabilities. We also use statsmodels to do some of the statistical analysis, in a workflow integrated with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the packages (or installing them, if needed)\n",
    "First we import the pandas (usually imported as \"pd\"), and statsmodels/numpy. We also use matplotlib for some visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting notes \n",
    "\n",
    "If you don't have these packages already, use pip3 to install them (using the terminal):\n",
    "* sudo pip3 install numpy\n",
    "* sudo pip3 install patsy\n",
    "* sudo pip3 install pandas\n",
    "* sudo pip3 install matplotlib\n",
    "* sudo pip3 install statsmodels\n",
    "\n",
    "If you get a gcc-error when installing any of the packages, run (in the terminal):\n",
    "* sudo apt-get install python3-dev\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading (or creating) data for Pandas\n",
    "\n",
    "One of the key advantages of Pandas is how flexible it is in terms of types of data or files that it can load, and that it can save into. But first, we can also simply create the data from scratch.\n",
    "\n",
    "For example, we can create a dataframe from lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['John', 'Mary', 'Stefan', 'Cristina']\n",
    "ages = [18, 20, 33, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_and_ages = list(zip(names, ages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = names_and_ages, columns = ['name', 'age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the dataframe that we created was called df. We could have used any other name - although in several tutorial and in stackexchange, usually people call a generic dataframe given as example as df.\n",
    "\n",
    "To see how the dataframe looks like, we can simply call it again (like any Python element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a list of dictionaries to create a dataframe. The advantage here is that Pandas automatically recognizes the keys in the dictionaries as being the column names. This can be especially handy when working with JSON, and data acquired via APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "people = [\n",
    "    {'name': 'John', 'age' : 20 , 'profession' : 'student', 'salary' : 10000},\n",
    "    {'name': 'Mary', 'age' : 33 , 'profession' : 'journalist', 'salary' : 50000},\n",
    "    {'name': 'Stefan', 'age' : 40, 'profession' : 'researcher', 'monthly_salary': 1500 },\n",
    "    {'name': 'Cristina', 'age' : 18, 'profession' : 'webmaster', 'salary' : 25000},\n",
    "    {'name': 'Joost', 'age' :22 , 'profession' : 'data scientist', 'salary' : 70000},\n",
    "    {'name': 'Sandra', 'age' : 34, 'profession' : 'journalist', 'salary' : 55000},\n",
    "    {'name': 'Marina', 'age' : 50, 'profession' : 'researcher', 'salary' : 45000 },\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how Stefan has a NaN in the salary column, and everybody else has a NaN in the monthly_salary column. The dictionary above only had Stefan with the key \"monthly_salary\", while everybody else had only \"salary\". Pandas treated everything that it could not find as missing data (NaN, which stands for \"Not a Number\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data into pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has several ways to load (or create) dataframes. You can read files (e.g., read_csv, read_excel, read_json), or even connect to databases. Likewise, you can save data in all these formats. For our tutorial, we will use a dataset of tweets collected from company accounts across several countries. \n",
    "\n",
    "The dataset is actually much larger than this (6M tweets and counting), but here we will use a random sample of 10K tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('brand_tweets_bdaca.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "One of the easiest ways to see what the dataset contains is to simply call the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The unnamed column does not seem to be that useful, so we can drop it. As a note, axis=1 means that we are dropping a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = tweets.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check which columns the dataset contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a note, the columns in the dataset mean the following:\n",
    "* utweet_id: Unique ID of the tweet\n",
    "* company: Company name\n",
    "* screenname: Twitter name of the company account\n",
    "* country: Country in which the company account is (mostly) active\n",
    "* idv, mas & uai: Hofstede's classification for Individualism, Masculinity & Uncertainty Avoidance of the given country\n",
    "* revenues: Revenues of the company\n",
    "* statuses_count: Total number of tweets that the company account has published\n",
    "* followers_count: Total number of followers that the company account has\n",
    "* created_at: Date and time in which the tweet was created\n",
    "* animated_gif, video, photo: Number of animated gifs, videos or photos published in the tweet\n",
    "* has_hash: Whether the tweet has a hashtag in the text\n",
    "* is_retweet: Whether the tweet is actually a retweet from someone else's account\n",
    "* is_reply: Whether the tweet is a reply to another user\n",
    "* rts: number of retweets that that tweet received\n",
    "\n",
    "As a note, the actual text is not included (to reduce the file size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dataset\n",
    "\n",
    "We made a small modification to the dataset, so we can save it. Pandas offers several formats to read/write data (see http://pandas.pydata.org/pandas-docs/stable/io.html). We'll use csv this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets.to_csv('brand_tweets_bdaca_corrected.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the dataset\n",
    "\n",
    "Pandas allows for a lot of exploratory analyses to be done directly with built-in functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, getting descriptives of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or getting frequencies from categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['screenname'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also group by a given category, and get the descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets.groupby(['company']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or just get the means of a specific column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets[['rts', 'company']].groupby(['company']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be clearer, in the previous step, we actually selected two columns of the dataframe when we requested tweets[['rts', 'screenname']]. We can also simply create a smaller dataframe with just a few columns of the larger dataframe, and then later perform operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subdf1 = tweets[['screenname', 'company']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subdf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter the dataframe. Say that we are only interested in the tweets from Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets[tweets['country'] == 'Germany']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data\n",
    "\n",
    "We can also run some quick data visualizations. For more information, see: http://pandas.pydata.org/pandas-docs/version/0.18.1/visualization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets.plot.scatter(x='statuses_count', y='followers_count', c='blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets.hist(column='statuses_count', alpha=.5, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some of the visualizations, we can ask several plots to be done at the same time. For example, we may want a histogram of statuses_count for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets.hist(column='statuses_count', by=['country'], alpha=.5, bins=10, figsize=(10,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running statistical tests\n",
    "\n",
    "While you could export the dataframe to CSV (or even to a STATA format) and to the statistical analysis elsewhere, Pandas & Statsmodels/Numpy allow you to do a lot of it in the same workflow. \n",
    "\n",
    "The examples below are just very small set of what these packages can do. To know more, check:\n",
    "* Pandas Computational Tools: http://pandas.pydata.org/pandas-docs/stable/computation.html\n",
    "* Statsmodels documentation: http://statsmodels.sourceforge.net/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do T-Tests. The results return the test statistic, p-value, and the degrees of freedom. \n",
    "\n",
    "Here, notice that we are using the ability to filter a dataframe (e.g., *tweets[tweets['country'] == 'Brazil']*  creates a dataframe only with Brazil as a country; adding *['rts']* at the end selects only the column for rts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ttest_ind(tweets[tweets['country'] == 'Brazil']['rts'], \n",
    "                               tweets[tweets['country'] == 'Netherlands']['rts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do an OLS regression. In order to do so, we need to define a model and then run it. When defining the model, you create the equation in the following manner:\n",
    "* First you include your dependent variable, followed by the ~ sign\n",
    "* Then you include the independent variables (separated by the + sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = 'rts ~ photo + video + followers_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regression = ols(formula=model, data=tweets).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(regression.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(regression.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can also run a series of models in a for loop, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = 'rts ~ followers_count'\n",
    "independent_variables = ['statuses_count', 'uai', 'idv', 'mas', 'photo', 'video', 'animated_gif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(sm.formula.api.ols(formula=base_model, data=tweets).fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for iv in independent_variables:\n",
    "    base_model += '+ ' + iv\n",
    "    models.append(sm.formula.api.ols(formula=base_model, data=tweets).fit())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print(model.summary())\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More information\n",
    "\n",
    "If you are interested in using Python for your statistical analyses, you may want to consult:\n",
    "* 10-minute video showcasing the possibilities of Pandas: https://vimeo.com/59324550\n",
    "* Doing time series analyses in Pandas: http://earthpy.org/pandas-basics.html & http://statsmodels.sourceforge.net/stable/vector_ar.html#var\n",
    "* And doing a deep dive in the Pandas documentation :-) http://pandas.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
